import os
import pickle
import pytesseract
import torch
import torch.nn as nn
import json
from torch.utils.data import DataLoader, TensorDataset
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from PIL import Image

# Useful things
folder_labels = {
    "ID": 0,
    "Medical Form": 1,
    "Receipts": 2
}

stop_words = [
    "the", "and", "is", "in", "of", "to", "a", "with", "for", "on",
    "at", "by", "this", "that", "an", "are", "was", "as", "from", "be"
]

important_words = [
    "id", "identification", "medical form", "receipt", "driver", "card"
]

def boost_keywords(text, keywords, multiplier=10):
        for word in keywords:
            if word.lower() in text.lower():
                text += (" " + word) * multiplier
        return text


class TextClassifier(nn.Module):
    def __init__(self, input_dim=1000, output_dim=3):
        super(TextClassifier, self).__init__()
        self.model = nn.Sequential(
            nn.Linear(input_dim, 64),
            nn.ReLU(),
            nn.Linear(64, output_dim),
        )

    def forward(self, x):
        return self.model(x)
    
    def fit(self, train_loader, epochs):
        optimizer = torch.optim.Adam(self.parameters(), lr=0.001)
        criterion = nn.CrossEntropyLoss()

        for epoch in range(epochs):
            for batch_x, batch_y in train_loader:
                optimizer.zero_grad()
                outputs = self(batch_x)
                loss = criterion(outputs, batch_y.squeeze().long())
                loss.backward()
                optimizer.step()
                torch.save(model.state_dict(), "text_classifier_model.pth")

            if (epoch + 1) % 50 == 0:
                print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')

if __name__ == "__main__":
    image_paths = []
    labels = []

    pytesseract.pytesseract.tesseract_cmd = r"C:\Program Files\Tesseract-OCR\tesseract.exe"

    valid_extensions = ('.png', '.jpg', '.jpeg', '.bmp', '.tiff')

    print("Loading images and labels...")

    for folder_name in os.listdir("DataSet"):
        folder_path = os.path.join("DataSet", folder_name)

        if not os.path.isdir(folder_path) or folder_name not in folder_labels:
            continue

        label = folder_labels[folder_name]

        for file_name in os.listdir(folder_path):
            if file_name.lower().endswith(valid_extensions):
                image_path = os.path.join(folder_path, file_name)
                image_paths.append(image_path)
                labels.append(label)

    with open("labels.json", "w") as f:
        json.dump(labels, f, indent=4)

    vectorizer = TfidfVectorizer(
        max_features=1000,
        ngram_range=(1, 2),
        stop_words=stop_words
        )

    print("Extracting text from images...")
    texts = []

    boosted_texts = [boost_keywords(t, important_words) for t in texts]

    texts = boosted_texts

    with open("texts.json", "r") as f:
        texts = json.load(f)

    x = vectorizer.fit_transform(texts).toarray()

    x = torch.tensor(x, dtype=torch.float32)
    y = torch.tensor(labels, dtype=torch.float32).view(-1, 1)

    dataset = TensorDataset(x, y)
    train_loader = DataLoader(dataset, batch_size=32, shuffle=True)

    
    model = TextClassifier(input_dim=x.shape[1], output_dim=len(folder_labels))
    print("Training the model...")
    model.fit(train_loader, epochs=100)

